{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-27T06:55:27.455088Z","iopub.execute_input":"2022-02-27T06:55:27.455667Z","iopub.status.idle":"2022-02-27T06:55:28.806479Z","shell.execute_reply.started":"2022-02-27T06:55:27.455573Z","shell.execute_reply":"2022-02-27T06:55:28.805741Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from torchtext.datasets import IMDB\nfrom torch.utils.data.dataset import random_split\n\n# step1: load and crete the dataset\ntrain_dataset = IMDB(split='train')\ntest_dataset = IMDB(split='test')\n\ntorch.manual_seed(1)\ntrain_dataset, valid_dataset = random_split(\nlist(train_dataset), [20000, 5000])","metadata":{"execution":{"iopub.status.busy":"2022-02-27T06:55:30.049540Z","iopub.execute_input":"2022-02-27T06:55:30.050073Z","iopub.status.idle":"2022-02-27T06:56:10.203935Z","shell.execute_reply.started":"2022-02-27T06:55:30.050018Z","shell.execute_reply":"2022-02-27T06:56:10.203156Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 67.7MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# find unique tokens (words)\n\nimport re\nfrom collections import Counter, OrderedDict\n\ntoken_counts = Counter()\n\ndef tokenizer(text):\n    text = re.sub('<[^>]*>', '', text)\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n        ' '.join(emoticons).replace('-', '')\n    tokenized = text.split()\n    return tokenized\n\nfor label, line in train_dataset:\n    tokens = tokenizer(line)\n    token_counts.update(tokens)\n\nprint('Vocab-size', len(token_counts))","metadata":{"execution":{"iopub.status.busy":"2022-02-27T06:56:10.205788Z","iopub.execute_input":"2022-02-27T06:56:10.206091Z","iopub.status.idle":"2022-02-27T06:56:14.686486Z","shell.execute_reply.started":"2022-02-27T06:56:10.206029Z","shell.execute_reply":"2022-02-27T06:56:14.685720Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Vocab-size 69023\n","output_type":"stream"}]},{"cell_type":"code","source":"## Step 3: encoding each unique token into integers\nfrom torchtext.vocab import vocab\n\nsorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\nordered_dict = OrderedDict(sorted_by_freq_tuples)\n\nvocab = vocab(ordered_dict)\n\nvocab.insert_token(\"<pad>\", 0)\nvocab.insert_token(\"<unk>\", 1)\nvocab.set_default_index(1)\n\nprint([vocab[token] for token in ['this', 'is', 'an', 'example']])","metadata":{"execution":{"iopub.status.busy":"2022-02-27T06:56:14.687815Z","iopub.execute_input":"2022-02-27T06:56:14.688088Z","iopub.status.idle":"2022-02-27T06:56:14.855547Z","shell.execute_reply.started":"2022-02-27T06:56:14.688040Z","shell.execute_reply":"2022-02-27T06:56:14.854684Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[11, 7, 35, 457]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 3-A: define the functions for transformation\n\ndevice = torch.device(\"cuda:0\")\n# device = 'cpu'\n\ntext_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\nlabel_pipeline = lambda x: 1. if x == 'pos' else 0.\n\n\n## Step 3-B: wrap the encode and transformation function\ndef collate_batch(batch):\n    label_list, text_list, lengths = [], [], []\n    for _label, _text in batch:\n        label_list.append(label_pipeline(_label))\n        processed_text = torch.tensor(text_pipeline(_text), \n                                      dtype=torch.int64)\n        text_list.append(processed_text)\n        lengths.append(processed_text.size(0))\n    label_list = torch.tensor(label_list)\n    lengths = torch.tensor(lengths)\n    padded_text_list = nn.utils.rnn.pad_sequence(\n        text_list, batch_first=True)\n    return padded_text_list.to(device), label_list.to(device), lengths.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:04.702956Z","iopub.execute_input":"2022-02-27T07:01:04.703250Z","iopub.status.idle":"2022-02-27T07:01:04.715506Z","shell.execute_reply.started":"2022-02-27T07:01:04.703220Z","shell.execute_reply":"2022-02-27T07:01:04.714852Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## Take a small batch\n\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\ntext_batch, label_batch, length_batch = next(iter(dataloader))\nprint(text_batch)\nprint(label_batch)\nprint(length_batch)\nprint(text_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:05.276188Z","iopub.execute_input":"2022-02-27T07:01:05.276816Z","iopub.status.idle":"2022-02-27T07:01:08.315105Z","shell.execute_reply.started":"2022-02-27T07:01:05.276780Z","shell.execute_reply":"2022-02-27T07:01:08.314353Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0],\n        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0],\n        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n            24,   887,    32,    31,    19,     8,    13,   428],\n        [18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n         10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n         18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n           289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0]],\n       device='cuda:0')\ntensor([1., 1., 1., 0.], device='cuda:0')\ntensor([165,  86, 218, 145], device='cuda:0')\ntorch.Size([4, 218])\n","output_type":"stream"}]},{"cell_type":"code","source":"## Step 4: batching the datasets\n\nbatch_size = 32  \n\ntrain_dl = DataLoader(train_dataset, batch_size=batch_size,\n                      shuffle=True, collate_fn=collate_batch)\nvalid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n                      shuffle=False, collate_fn=collate_batch)\ntest_dl = DataLoader(test_dataset, batch_size=batch_size,\n                     shuffle=False, collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:08.316719Z","iopub.execute_input":"2022-02-27T07:01:08.317123Z","iopub.status.idle":"2022-02-27T07:01:08.323185Z","shell.execute_reply.started":"2022-02-27T07:01:08.317085Z","shell.execute_reply":"2022-02-27T07:01:08.322347Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"embedding = nn.Embedding(num_embeddings=10, \n                         embedding_dim=3, \n                         padding_idx=0)\n \n# a batch of 2 samples of 4 indices each\ntext_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\nprint(embedding(text_encoded_input))","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:08.324545Z","iopub.execute_input":"2022-02-27T07:01:08.325030Z","iopub.status.idle":"2022-02-27T07:01:08.350554Z","shell.execute_reply.started":"2022-02-27T07:01:08.324992Z","shell.execute_reply":"2022-02-27T07:01:08.349740Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"tensor([[[ 0.7039, -0.8321, -0.4651],\n         [-0.3203,  2.2408,  0.5566],\n         [-0.4643,  0.3046,  0.7046],\n         [-0.7106, -0.2959,  0.8356]],\n\n        [[-0.4643,  0.3046,  0.7046],\n         [ 0.0946, -0.3531,  0.9124],\n         [-0.3203,  2.2408,  0.5566],\n         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward>)\n","output_type":"stream"}]},{"cell_type":"code","source":"## An example of building a RNN model\n## with simple RNN layer\n\n# Fully connected neural network with one hidden layer\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.rnn = nn.RNN(input_size, \n                          hidden_size, \n                          num_layers=2, \n                          batch_first=True)\n        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, 1)\n        \n    def forward(self, x):\n        _, hidden = self.rnn(x)\n        out = hidden[-1, :, :]\n        out = self.fc(out)\n        return out\n\nmodel = RNN(64, 32) \n\nprint(model) \n \nmodel(torch.randn(5, 3, 64)) ","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:08.352650Z","iopub.execute_input":"2022-02-27T07:01:08.352973Z","iopub.status.idle":"2022-02-27T07:01:08.417911Z","shell.execute_reply.started":"2022-02-27T07:01:08.352938Z","shell.execute_reply":"2022-02-27T07:01:08.417114Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"RNN(\n  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=32, out_features=1, bias=True)\n)\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.3183],\n        [ 0.1230],\n        [ 0.1772],\n        [-0.1052],\n        [-0.1259]], grad_fn=<AddmmBackward>)"},"metadata":{}}]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, \n                                      embed_dim, \n                                      padding_idx=0) \n        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n                           batch_first=True)\n        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(fc_hidden_size, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, text, lengths):\n        out = self.embedding(text)\n        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n        out, (hidden, cell) = self.rnn(out)\n        out = hidden[-1, :, :]\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.fc2(out)\n        out = self.sigmoid(out)\n        return out\n         \nvocab_size = len(vocab)\nembed_dim = 20\nrnn_hidden_size = 64\nfc_hidden_size = 64\n\ntorch.manual_seed(1)\nmodel = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:08.419419Z","iopub.execute_input":"2022-02-27T07:01:08.419663Z","iopub.status.idle":"2022-02-27T07:01:09.112630Z","shell.execute_reply.started":"2022-02-27T07:01:08.419630Z","shell.execute_reply":"2022-02-27T07:01:09.111873Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train(dataloader):\n    model.train()\n    total_acc, total_loss = 0, 0\n    for text_batch, label_batch, lengths in dataloader:\n        optimizer.zero_grad()\n        pred = model(text_batch, lengths)[:, 0]\n        loss = loss_fn(pred, label_batch)\n        loss.backward()\n        optimizer.step()\n        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n        total_loss += loss.item()*label_batch.size(0)\n    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n \ndef evaluate(dataloader):\n    model.eval()\n    total_acc, total_loss = 0, 0\n    with torch.no_grad():\n        for text_batch, label_batch, lengths in dataloader:\n            pred = model(text_batch, lengths)[:, 0]\n            loss = loss_fn(pred, label_batch)\n            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n            total_loss += loss.item()*label_batch.size(0)\n    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:09.113976Z","iopub.execute_input":"2022-02-27T07:01:09.114239Z","iopub.status.idle":"2022-02-27T07:01:09.124152Z","shell.execute_reply.started":"2022-02-27T07:01:09.114205Z","shell.execute_reply":"2022-02-27T07:01:09.123254Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 10 \n\ntorch.manual_seed(1)\n \nfor epoch in range(num_epochs):\n    acc_train, loss_train = train(train_dl)\n    acc_valid, loss_valid = evaluate(valid_dl)\n    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:01:09.126641Z","iopub.execute_input":"2022-02-27T07:01:09.127261Z","iopub.status.idle":"2022-02-27T07:06:11.291924Z","shell.execute_reply.started":"2022-02-27T07:01:09.127212Z","shell.execute_reply":"2022-02-27T07:06:11.291215Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 0 accuracy: 0.5986 val_accuracy: 0.6538\nEpoch 1 accuracy: 0.6914 val_accuracy: 0.7078\nEpoch 2 accuracy: 0.7800 val_accuracy: 0.7674\nEpoch 3 accuracy: 0.8325 val_accuracy: 0.8182\nEpoch 4 accuracy: 0.8733 val_accuracy: 0.8156\nEpoch 5 accuracy: 0.8926 val_accuracy: 0.8390\nEpoch 6 accuracy: 0.9077 val_accuracy: 0.8300\nEpoch 7 accuracy: 0.9257 val_accuracy: 0.8254\nEpoch 8 accuracy: 0.9375 val_accuracy: 0.8512\nEpoch 9 accuracy: 0.9536 val_accuracy: 0.8566\n","output_type":"stream"}]},{"cell_type":"code","source":"acc_test, _ = evaluate(test_dl)\nprint(f'test_accuracy: {acc_test:.4f}') ","metadata":{"execution":{"iopub.status.busy":"2022-02-27T07:06:11.293637Z","iopub.execute_input":"2022-02-27T07:06:11.293885Z","iopub.status.idle":"2022-02-27T07:06:30.247838Z","shell.execute_reply.started":"2022-02-27T07:06:11.293851Z","shell.execute_reply":"2022-02-27T07:06:30.247111Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"test_accuracy: 0.8501\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}