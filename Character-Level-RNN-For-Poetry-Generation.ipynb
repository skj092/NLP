{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nimport torchtext\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:19:54.211524Z","iopub.execute_input":"2022-03-09T12:19:54.212150Z","iopub.status.idle":"2022-03-09T12:19:55.723081Z","shell.execute_reply.started":"2022-03-09T12:19:54.212047Z","shell.execute_reply":"2022-03-09T12:19:55.722306Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"files = glob(f'../input/poemsdataset/forms/**/*.txt')\nfiles[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:20.225477Z","iopub.execute_input":"2022-03-09T12:20:20.225761Z","iopub.status.idle":"2022-03-09T12:20:22.402577Z","shell.execute_reply.started":"2022-03-09T12:20:20.225731Z","shell.execute_reply":"2022-03-09T12:20:22.401872Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['../input/poemsdataset/forms/lay/LayPoemsLayAGarlandOnMyHearsePoembyFrancisBeaumont.txt',\n '../input/poemsdataset/forms/lay/LayPoemsLayHisSwordByHisSidePoembyThomasMoore.txt',\n '../input/poemsdataset/forms/lay/LayPoemsLayAGarlandOnMyHearsePoembyBeaumontandFletcher.txt',\n '../input/poemsdataset/forms/lay/LayPoemsAsILayWithHeadInYourLapCameradoPoembyWaltWhitman.txt',\n '../input/poemsdataset/forms/lay/LayPoemsTheDeerLayDownTheirBonesPoembyRobinsonJeffers.txt']"},"metadata":{}}]},{"cell_type":"code","source":"len(files)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:22.403996Z","iopub.execute_input":"2022-03-09T12:20:22.405062Z","iopub.status.idle":"2022-03-09T12:20:22.410588Z","shell.execute_reply.started":"2022-03-09T12:20:22.405019Z","shell.execute_reply":"2022-03-09T12:20:22.409970Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"6322"},"metadata":{}}]},{"cell_type":"code","source":"all_texts = [open(f, encoding='utf8').read() for f in files]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:24.291055Z","iopub.execute_input":"2022-03-09T12:20:24.291319Z","iopub.status.idle":"2022-03-09T12:20:52.007399Z","shell.execute_reply.started":"2022-03-09T12:20:24.291288Z","shell.execute_reply":"2022-03-09T12:20:52.006671Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"text = [f for sublist in all_texts for f in sublist]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:52.010777Z","iopub.execute_input":"2022-03-09T12:20:52.011065Z","iopub.status.idle":"2022-03-09T12:20:52.183556Z","shell.execute_reply.started":"2022-03-09T12:20:52.011036Z","shell.execute_reply":"2022-03-09T12:20:52.182811Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"char_set = set(text)\n\nprint('Total Length:', len(text))\nprint('Unique characters:', len(char_set))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:52.184641Z","iopub.execute_input":"2022-03-09T12:20:52.184882Z","iopub.status.idle":"2022-03-09T12:20:52.236495Z","shell.execute_reply.started":"2022-03-09T12:20:52.184849Z","shell.execute_reply":"2022-03-09T12:20:52.235824Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total Length: 6697076\nUnique characters: 1054\n","output_type":"stream"}]},{"cell_type":"code","source":"chars_sorted = sorted(char_set)\nchar2int = {ch:i for i, ch in enumerate(chars_sorted)}\n\nchar_array = np.array(chars_sorted)\n\ntext_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n\nprint('Text encoded shape: ', text_encoded.shape)\n\nprint(text[:15], '     == Encoding ==> ', text_encoded[:15])\nprint(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:52.238492Z","iopub.execute_input":"2022-03-09T12:20:52.238881Z","iopub.status.idle":"2022-03-09T12:20:53.047403Z","shell.execute_reply.started":"2022-03-09T12:20:52.238845Z","shell.execute_reply":"2022-03-09T12:20:53.046644Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Text encoded shape:  (6697076,)\n['L', 'a', 'y', ' ', 'a', ' ', 'g', 'a', 'r', 'l', 'a', 'n', 'd', ' ', 'o']      == Encoding ==>  [47 68 92  3 68  3 74 68 85 79 68 81 71  3 82]\n[81  3 80 92  3 75]  == Reverse  ==>  n my h\n","output_type":"stream"}]},{"cell_type":"code","source":"len(text), len(text_encoded)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:53.048672Z","iopub.execute_input":"2022-03-09T12:20:53.048937Z","iopub.status.idle":"2022-03-09T12:20:53.056726Z","shell.execute_reply.started":"2022-03-09T12:20:53.048886Z","shell.execute_reply":"2022-03-09T12:20:53.055891Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(6697076, 6697076)"},"metadata":{}}]},{"cell_type":"code","source":"for ex in text_encoded[:5]:\n    print('{} -> {}'.format(ex, char_array[ex]))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:53.057929Z","iopub.execute_input":"2022-03-09T12:20:53.058248Z","iopub.status.idle":"2022-03-09T12:20:53.065667Z","shell.execute_reply.started":"2022-03-09T12:20:53.058215Z","shell.execute_reply":"2022-03-09T12:20:53.064746Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"47 -> L\n68 -> a\n92 -> y\n3 ->  \n68 -> a\n","output_type":"stream"}]},{"cell_type":"code","source":"seq_length = 20\nchunk_size = seq_length + 1\n\ntext_chunks = [text_encoded[i:i+chunk_size] \n               for i in range(len(text_encoded)-chunk_size)] \n\n## inspection:\nfor seq in text_chunks[:1]:\n    input_seq = seq[:seq_length]\n    target = seq[seq_length] \n    print(input_seq, ' -> ', target)\n    print(repr(''.join(char_array[input_seq])), \n          ' -> ', repr(''.join(char_array[target])))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:53.066987Z","iopub.execute_input":"2022-03-09T12:20:53.067471Z","iopub.status.idle":"2022-03-09T12:20:55.770640Z","shell.execute_reply.started":"2022-03-09T12:20:53.067425Z","shell.execute_reply":"2022-03-09T12:20:55.769087Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[47 68 92  3 68  3 74 68 85 79 68 81 71  3 82 81  3 80 92  3]  ->  75\n'Lay a garland on my '  ->  'h'\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass TextDataset(Dataset):\n    def __init__(self, text_chunks):\n        self.text_chunks = text_chunks\n\n    def __len__(self):\n        return len(self.text_chunks)\n    \n    def __getitem__(self, idx):\n        text_chunk = self.text_chunks[idx]\n        return text_chunk[:-1].long(), text_chunk[1:].long()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:55.771786Z","iopub.execute_input":"2022-03-09T12:20:55.772149Z","iopub.status.idle":"2022-03-09T12:20:55.778894Z","shell.execute_reply.started":"2022-03-09T12:20:55.772101Z","shell.execute_reply":"2022-03-09T12:20:55.778064Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"seq_dataset = TextDataset(torch.tensor(text_chunks))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:20:55.780208Z","iopub.execute_input":"2022-03-09T12:20:55.780516Z","iopub.status.idle":"2022-03-09T12:21:22.325667Z","shell.execute_reply.started":"2022-03-09T12:20:55.780481Z","shell.execute_reply":"2022-03-09T12:21:22.324827Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for i, (seq, target) in enumerate(seq_dataset):\n    print(' Input (x):', repr(''.join(char_array[seq])))\n    print('Target (y):', repr(''.join(char_array[target])))\n    print()\n    if i == 1:\n        break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:21:22.328460Z","iopub.execute_input":"2022-03-09T12:21:22.328711Z","iopub.status.idle":"2022-03-09T12:21:22.354366Z","shell.execute_reply.started":"2022-03-09T12:21:22.328673Z","shell.execute_reply":"2022-03-09T12:21:22.353556Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":" Input (x): 'Lay a garland on my '\nTarget (y): 'ay a garland on my h'\n\n Input (x): 'ay a garland on my h'\nTarget (y): 'y a garland on my he'\n\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")\n# device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:21:22.355747Z","iopub.execute_input":"2022-03-09T12:21:22.356034Z","iopub.status.idle":"2022-03-09T12:21:22.361180Z","shell.execute_reply.started":"2022-03-09T12:21:22.355998Z","shell.execute_reply":"2022-03-09T12:21:22.360244Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n \nbatch_size = 64\n\ntorch.manual_seed(1)\nseq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:21:22.362919Z","iopub.execute_input":"2022-03-09T12:21:22.363197Z","iopub.status.idle":"2022-03-09T12:21:22.372115Z","shell.execute_reply.started":"2022-03-09T12:21:22.363162Z","shell.execute_reply":"2022-03-09T12:21:22.371343Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(seq_dataset), len(seq_dl)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:21:22.373611Z","iopub.execute_input":"2022-03-09T12:21:22.373964Z","iopub.status.idle":"2022-03-09T12:21:22.380349Z","shell.execute_reply.started":"2022-03-09T12:21:22.373899Z","shell.execute_reply":"2022-03-09T12:21:22.379367Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(6697055, 104641)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Building a character-level RNN model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim) \n        self.rnn_hidden_size = rnn_hidden_size\n        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n                           batch_first=True)\n        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n\n    def forward(self, x, hidden, cell):\n        out = self.embedding(x).unsqueeze(1)\n        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n        out = self.fc(out).reshape(out.size(0), -1)\n        return out, hidden, cell\n\n    def init_hidden(self, batch_size):\n        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n        return hidden.to(device), cell.to(device)\n    \nvocab_size = len(char_array)\nembed_dim = 64\nrnn_hidden_size = 64\n\ntorch.manual_seed(1)\nmodel = RNN(vocab_size, embed_dim, rnn_hidden_size) \nmodel = model.to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:21:22.382080Z","iopub.execute_input":"2022-03-09T12:21:22.382617Z","iopub.status.idle":"2022-03-09T12:21:26.119152Z","shell.execute_reply.started":"2022-03-09T12:21:22.382584Z","shell.execute_reply":"2022-03-09T12:21:26.118491Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"RNN(\n  (embedding): Embedding(1054, 64)\n  (rnn): LSTM(64, 64, batch_first=True)\n  (fc): Linear(in_features=64, out_features=1054, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 10000\n\ntorch.manual_seed(1)\n\nfor epoch in range(num_epochs):\n    hidden, cell = model.init_hidden(batch_size)\n    seq_batch, target_batch = next(iter(seq_dl))\n    seq_batch = seq_batch.to(device)\n    target_batch = target_batch.to(device)\n    optimizer.zero_grad()\n    loss = 0\n    for c in range(seq_length):\n        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n        loss += loss_fn(pred, target_batch[:, c])\n    loss.backward()\n    optimizer.step()\n    loss = loss.item()/seq_length\n    if epoch % 500 == 0:\n        print(f'Epoch {epoch} loss: {loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:21:26.120445Z","iopub.execute_input":"2022-03-09T12:21:26.120692Z","iopub.status.idle":"2022-03-09T14:17:37.777465Z","shell.execute_reply.started":"2022-03-09T12:21:26.120657Z","shell.execute_reply":"2022-03-09T14:17:37.776627Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 0 loss: 6.9602\nEpoch 500 loss: 2.6471\nEpoch 1000 loss: 2.3748\nEpoch 1500 loss: 2.3142\nEpoch 2000 loss: 2.3239\nEpoch 2500 loss: 2.3572\nEpoch 3000 loss: 2.1681\nEpoch 3500 loss: 2.1780\nEpoch 4000 loss: 2.1150\nEpoch 4500 loss: 2.0841\nEpoch 5000 loss: 2.1928\nEpoch 5500 loss: 2.1314\nEpoch 6000 loss: 2.1072\nEpoch 6500 loss: 1.9743\nEpoch 7000 loss: 2.0691\nEpoch 7500 loss: 2.0408\nEpoch 8000 loss: 2.0885\nEpoch 8500 loss: 2.0165\nEpoch 9000 loss: 2.0640\nEpoch 9500 loss: 2.0229\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.distributions.categorical import Categorical\n\ndef sample(model, starting_str, \n           len_generated_text=500, \n           scale_factor=1.0):\n\n    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n    encoded_input = torch.reshape(encoded_input, (1, -1))\n\n    generated_str = starting_str\n\n    model.eval()\n    hidden, cell = model.init_hidden(1)\n    hidden = hidden.to('cpu')\n    cell = cell.to('cpu')\n    for c in range(len(starting_str)-1):\n        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell) \n    \n    last_char = encoded_input[:, -1]\n    for i in range(len_generated_text):\n        logits, hidden, cell = model(last_char.view(1), hidden, cell) \n        logits = torch.squeeze(logits, 0)\n        scaled_logits = logits * scale_factor\n        m = Categorical(logits=scaled_logits)\n        last_char = m.sample()\n        generated_str += str(char_array[last_char])\n        \n    return generated_str\n\ntorch.manual_seed(1)\nmodel.to('cpu')\nprint(sample(model, starting_str='The island'))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:17:37.778851Z","iopub.execute_input":"2022-03-09T14:17:37.779133Z","iopub.status.idle":"2022-03-09T14:17:38.092688Z","shell.execute_reply.started":"2022-03-09T14:17:37.779098Z","shell.execute_reply":"2022-03-09T14:17:38.091956Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"The island call love his and suétor by in too weel deem, bless to thight cheef daughs of teathings cynempictrymenten's, with crears wech menoty set nears camain.X.\nThe neak.\nA fas wish is to knop con\nHand soulds\nCronger-moor, I wnoinialtrains a wordghing in the chee\nIrrated to me , ald the addous live\nhout to to patter wilf bey over bordibark shown,\nOf the sink warl;\nXst doin'd smake of Ca giver.\nAnd gellious the woult,\nBood and reature-past to, sfaid and excher,)\"\nShe lay wanky then' perplied thing, seep\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://github.com/rasbt/machine-learning-book/blob/main/ch15/ch15_part3.ipynb","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:31:43.780793Z","iopub.status.idle":"2022-03-09T07:31:43.781449Z","shell.execute_reply.started":"2022-03-09T07:31:43.781207Z","shell.execute_reply":"2022-03-09T07:31:43.781231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample(model, starting_str='The silence tree'))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:20:27.512042Z","iopub.execute_input":"2022-03-09T14:20:27.512748Z","iopub.status.idle":"2022-03-09T14:20:27.745633Z","shell.execute_reply.started":"2022-03-09T14:20:27.512712Z","shell.execute_reply":"2022-03-09T14:20:27.744863Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"The silence tree my fate/1\nThe fust think rodum do nothould; at Gatu wial cruckled moterness with man\nBate spirgued now dore they\nTo ulsoners to they usen's sautor comes to take,\nThis flownim nots!\nWhines\nAnto fare,\nHe vin by outhous, , a eoces the fan rail stausly, Reza do of roose foroched my ge a catched beat comion.Yess an love wafts rince, sacally is follave of musccitish sheind or eiv tyink the gell away\ntrure now dorgay:\nall the verround,\nAn greass of bear,\nOu toem' the schiffed them loid.\nWher bacting a\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sample(model, starting_str='The silence tree',len_generated_text=50))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:21:08.894236Z","iopub.execute_input":"2022-03-09T14:21:08.894532Z","iopub.status.idle":"2022-03-09T14:21:08.927541Z","shell.execute_reply.started":"2022-03-09T14:21:08.894497Z","shell.execute_reply":"2022-03-09T14:21:08.926715Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"The silence tree!\nNor wab thear all somate up birm at the erchill \n","output_type":"stream"}]},{"cell_type":"code","source":"print(sample(model, starting_str='In the end',len_generated_text=50))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:21:25.702957Z","iopub.execute_input":"2022-03-09T14:21:25.703585Z","iopub.status.idle":"2022-03-09T14:21:25.742145Z","shell.execute_reply.started":"2022-03-09T14:21:25.703544Z","shell.execute_reply":"2022-03-09T14:21:25.741248Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"In the ends,\nright\nher fide dival to their sun,\nNocks;\nselt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sample(model, starting_str='I see the light',len_generated_text=100))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:22:24.675247Z","iopub.execute_input":"2022-03-09T14:22:24.675508Z","iopub.status.idle":"2022-03-09T14:22:24.730407Z","shell.execute_reply.started":"2022-03-09T14:22:24.675470Z","shell.execute_reply":"2022-03-09T14:22:24.729601Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"I see the light ©4 6ই prais, cruthereswing wonded hin humme,\n'ou blowry and res\ntheir grave;\nLoviced seete his came\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}