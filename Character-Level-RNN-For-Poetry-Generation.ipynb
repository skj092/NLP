{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nimport torchtext\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:32:54.113035Z","iopub.execute_input":"2022-03-09T10:32:54.113507Z","iopub.status.idle":"2022-03-09T10:32:55.976920Z","shell.execute_reply.started":"2022-03-09T10:32:54.113417Z","shell.execute_reply":"2022-03-09T10:32:55.975989Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"files = glob(f'../input/poemsdataset/forms/**/*.txt')\nfiles[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:32:55.979013Z","iopub.execute_input":"2022-03-09T10:32:55.979308Z","iopub.status.idle":"2022-03-09T10:32:59.427347Z","shell.execute_reply.started":"2022-03-09T10:32:55.979268Z","shell.execute_reply":"2022-03-09T10:32:59.426397Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['../input/poemsdataset/forms/lay/LayPoemsLayAGarlandOnMyHearsePoembyFrancisBeaumont.txt',\n '../input/poemsdataset/forms/lay/LayPoemsLayHisSwordByHisSidePoembyThomasMoore.txt',\n '../input/poemsdataset/forms/lay/LayPoemsLayAGarlandOnMyHearsePoembyBeaumontandFletcher.txt',\n '../input/poemsdataset/forms/lay/LayPoemsAsILayWithHeadInYourLapCameradoPoembyWaltWhitman.txt',\n '../input/poemsdataset/forms/lay/LayPoemsTheDeerLayDownTheirBonesPoembyRobinsonJeffers.txt']"},"metadata":{}}]},{"cell_type":"code","source":"len(files)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:33:32.504789Z","iopub.execute_input":"2022-03-09T10:33:32.505097Z","iopub.status.idle":"2022-03-09T10:33:32.512201Z","shell.execute_reply.started":"2022-03-09T10:33:32.505064Z","shell.execute_reply":"2022-03-09T10:33:32.511032Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"6322"},"metadata":{}}]},{"cell_type":"code","source":"all_texts = [open(f, encoding='utf8').read() for f in files[:2000]]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:46.271474Z","iopub.execute_input":"2022-03-09T10:51:46.271806Z","iopub.status.idle":"2022-03-09T10:51:47.526282Z","shell.execute_reply.started":"2022-03-09T10:51:46.271775Z","shell.execute_reply":"2022-03-09T10:51:47.525272Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"text = [f for sublist in all_texts for f in sublist]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:47.528561Z","iopub.execute_input":"2022-03-09T10:51:47.528917Z","iopub.status.idle":"2022-03-09T10:51:47.595275Z","shell.execute_reply.started":"2022-03-09T10:51:47.528820Z","shell.execute_reply":"2022-03-09T10:51:47.594373Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"char_set = set(text)\n\nprint('Total Length:', len(text))\nprint('Unique characters:', len(char_set))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:47.596973Z","iopub.execute_input":"2022-03-09T10:51:47.597306Z","iopub.status.idle":"2022-03-09T10:51:47.620690Z","shell.execute_reply.started":"2022-03-09T10:51:47.597265Z","shell.execute_reply":"2022-03-09T10:51:47.619430Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Total Length: 2025685\nUnique characters: 311\n","output_type":"stream"}]},{"cell_type":"code","source":"chars_sorted = sorted(char_set)\nchar2int = {ch:i for i, ch in enumerate(chars_sorted)}\n\nchar_array = np.array(chars_sorted)\n\ntext_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n\nprint('Text encoded shape: ', text_encoded.shape)\n\nprint(text[:15], '     == Encoding ==> ', text_encoded[:15])\nprint(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:47.623406Z","iopub.execute_input":"2022-03-09T10:51:47.624049Z","iopub.status.idle":"2022-03-09T10:51:47.895194Z","shell.execute_reply.started":"2022-03-09T10:51:47.624002Z","shell.execute_reply":"2022-03-09T10:51:47.894267Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Text encoded shape:  (2025685,)\n['L', 'a', 'y', ' ', 'a', ' ', 'g', 'a', 'r', 'l', 'a', 'n', 'd', ' ', 'o']      == Encoding ==>  [46 67 91  2 67  2 73 67 84 78 67 80 70  2 81]\n[80  2 79 91  2 74]  == Reverse  ==>  n my h\n","output_type":"stream"}]},{"cell_type":"code","source":"len(text), len(text_encoded)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:48.027624Z","iopub.execute_input":"2022-03-09T10:51:48.027863Z","iopub.status.idle":"2022-03-09T10:51:48.038161Z","shell.execute_reply.started":"2022-03-09T10:51:48.027832Z","shell.execute_reply":"2022-03-09T10:51:48.035009Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(2025685, 2025685)"},"metadata":{}}]},{"cell_type":"code","source":"for ex in text_encoded[:5]:\n    print('{} -> {}'.format(ex, char_array[ex]))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:48.348952Z","iopub.execute_input":"2022-03-09T10:51:48.349250Z","iopub.status.idle":"2022-03-09T10:51:48.356230Z","shell.execute_reply.started":"2022-03-09T10:51:48.349198Z","shell.execute_reply":"2022-03-09T10:51:48.355260Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"46 -> L\n67 -> a\n91 -> y\n2 ->  \n67 -> a\n","output_type":"stream"}]},{"cell_type":"code","source":"seq_length = 20\nchunk_size = seq_length + 1\n\ntext_chunks = [text_encoded[i:i+chunk_size] \n               for i in range(len(text_encoded)-chunk_size)] \n\n## inspection:\nfor seq in text_chunks[:1]:\n    input_seq = seq[:seq_length]\n    target = seq[seq_length] \n    print(input_seq, ' -> ', target)\n    print(repr(''.join(char_array[input_seq])), \n          ' -> ', repr(''.join(char_array[target])))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:48.777742Z","iopub.execute_input":"2022-03-09T10:51:48.778047Z","iopub.status.idle":"2022-03-09T10:51:50.299688Z","shell.execute_reply.started":"2022-03-09T10:51:48.778003Z","shell.execute_reply":"2022-03-09T10:51:50.298378Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"[46 67 91  2 67  2 73 67 84 78 67 80 70  2 81 80  2 79 91  2]  ->  74\n'Lay a garland on my '  ->  'h'\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass TextDataset(Dataset):\n    def __init__(self, text_chunks):\n        self.text_chunks = text_chunks\n\n    def __len__(self):\n        return len(self.text_chunks)\n    \n    def __getitem__(self, idx):\n        text_chunk = self.text_chunks[idx]\n        return text_chunk[:-1].long(), text_chunk[1:].long()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:50.301921Z","iopub.execute_input":"2022-03-09T10:51:50.302240Z","iopub.status.idle":"2022-03-09T10:51:50.323034Z","shell.execute_reply.started":"2022-03-09T10:51:50.302178Z","shell.execute_reply":"2022-03-09T10:51:50.322019Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"seq_dataset = TextDataset(torch.tensor(text_chunks))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:50.328785Z","iopub.execute_input":"2022-03-09T10:51:50.331766Z","iopub.status.idle":"2022-03-09T10:51:59.143887Z","shell.execute_reply.started":"2022-03-09T10:51:50.331721Z","shell.execute_reply":"2022-03-09T10:51:59.142727Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for i, (seq, target) in enumerate(seq_dataset):\n    print(' Input (x):', repr(''.join(char_array[seq])))\n    print('Target (y):', repr(''.join(char_array[target])))\n    print()\n    if i == 1:\n        break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:59.146788Z","iopub.execute_input":"2022-03-09T10:51:59.147143Z","iopub.status.idle":"2022-03-09T10:51:59.216096Z","shell.execute_reply.started":"2022-03-09T10:51:59.147102Z","shell.execute_reply":"2022-03-09T10:51:59.214896Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":" Input (x): 'Lay a garland on my '\nTarget (y): 'ay a garland on my h'\n\n Input (x): 'ay a garland on my h'\nTarget (y): 'y a garland on my he'\n\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")\n# device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:59.217872Z","iopub.execute_input":"2022-03-09T10:51:59.218372Z","iopub.status.idle":"2022-03-09T10:51:59.225159Z","shell.execute_reply.started":"2022-03-09T10:51:59.218285Z","shell.execute_reply":"2022-03-09T10:51:59.223955Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n \nbatch_size = 64\n\ntorch.manual_seed(1)\nseq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:59.226875Z","iopub.execute_input":"2022-03-09T10:51:59.227822Z","iopub.status.idle":"2022-03-09T10:51:59.238882Z","shell.execute_reply.started":"2022-03-09T10:51:59.227776Z","shell.execute_reply":"2022-03-09T10:51:59.237906Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"len(seq_dataset), len(seq_dl)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:59.240510Z","iopub.execute_input":"2022-03-09T10:51:59.241301Z","iopub.status.idle":"2022-03-09T10:51:59.252666Z","shell.execute_reply.started":"2022-03-09T10:51:59.241254Z","shell.execute_reply":"2022-03-09T10:51:59.251478Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"(2025664, 31651)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Building a character-level RNN model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim) \n        self.rnn_hidden_size = rnn_hidden_size\n        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n                           batch_first=True)\n        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n\n    def forward(self, x, hidden, cell):\n        out = self.embedding(x).unsqueeze(1)\n        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n        out = self.fc(out).reshape(out.size(0), -1)\n        return out, hidden, cell\n\n    def init_hidden(self, batch_size):\n        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n        return hidden.to(device), cell.to(device)\n    \nvocab_size = len(char_array)\nembed_dim = 64\nrnn_hidden_size = 64\n\ntorch.manual_seed(1)\nmodel = RNN(vocab_size, embed_dim, rnn_hidden_size) \nmodel = model.to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:51:59.254428Z","iopub.execute_input":"2022-03-09T10:51:59.255734Z","iopub.status.idle":"2022-03-09T10:51:59.278691Z","shell.execute_reply.started":"2022-03-09T10:51:59.255689Z","shell.execute_reply":"2022-03-09T10:51:59.277628Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"RNN(\n  (embedding): Embedding(311, 64)\n  (rnn): LSTM(64, 64, batch_first=True)\n  (fc): Linear(in_features=64, out_features=311, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 10000\n\ntorch.manual_seed(1)\n\nfor epoch in range(num_epochs):\n    hidden, cell = model.init_hidden(batch_size)\n    seq_batch, target_batch = next(iter(seq_dl))\n    seq_batch = seq_batch.to(device)\n    target_batch = target_batch.to(device)\n    optimizer.zero_grad()\n    loss = 0\n    for c in range(seq_length):\n        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n        loss += loss_fn(pred, target_batch[:, c])\n    loss.backward()\n    optimizer.step()\n    loss = loss.item()/seq_length\n    if epoch % 500 == 0:\n        print(f'Epoch {epoch} loss: {loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:52:00.744175Z","iopub.execute_input":"2022-03-09T10:52:00.744485Z","iopub.status.idle":"2022-03-09T11:27:29.673608Z","shell.execute_reply.started":"2022-03-09T10:52:00.744453Z","shell.execute_reply":"2022-03-09T11:27:29.672624Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Epoch 0 loss: 5.7540\nEpoch 500 loss: 2.5926\nEpoch 1000 loss: 2.4624\nEpoch 1500 loss: 2.3914\nEpoch 2000 loss: 2.3157\nEpoch 2500 loss: 2.2121\nEpoch 3000 loss: 2.1496\nEpoch 3500 loss: 2.1315\nEpoch 4000 loss: 2.1071\nEpoch 4500 loss: 2.1271\nEpoch 5000 loss: 2.0341\nEpoch 5500 loss: 2.1391\nEpoch 6000 loss: 1.9936\nEpoch 6500 loss: 2.1497\nEpoch 7000 loss: 1.9627\nEpoch 7500 loss: 2.0165\nEpoch 8000 loss: 2.0778\nEpoch 8500 loss: 2.0017\nEpoch 9000 loss: 1.9117\nEpoch 9500 loss: 1.9623\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.distributions.categorical import Categorical\n\ndef sample(model, starting_str, \n           len_generated_text=500, \n           scale_factor=1.0):\n\n    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n    encoded_input = torch.reshape(encoded_input, (1, -1))\n\n    generated_str = starting_str\n\n    model.eval()\n    hidden, cell = model.init_hidden(1)\n    hidden = hidden.to('cpu')\n    cell = cell.to('cpu')\n    for c in range(len(starting_str)-1):\n        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell) \n    \n    last_char = encoded_input[:, -1]\n    for i in range(len_generated_text):\n        logits, hidden, cell = model(last_char.view(1), hidden, cell) \n        logits = torch.squeeze(logits, 0)\n        scaled_logits = logits * scale_factor\n        m = Categorical(logits=scaled_logits)\n        last_char = m.sample()\n        generated_str += str(char_array[last_char])\n        \n    return generated_str\n\ntorch.manual_seed(1)\nmodel.to('cpu')\nprint(sample(model, starting_str='The island'))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T11:27:29.675638Z","iopub.execute_input":"2022-03-09T11:27:29.675937Z","iopub.status.idle":"2022-03-09T11:27:29.967651Z","shell.execute_reply.started":"2022-03-09T11:27:29.675893Z","shell.execute_reply":"2022-03-09T11:27:29.966670Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"The island\nGift is light and súts,\nBy heirly well chanes her hould unnvence!\nNo leight stant;\nThy côritup; toul sone whrow beside: © Musediont gay halled all thy for on depre lat wing,\nThough,\nAffel\nI kill; I waltime the conk it.               Af Brisish, Michael N'Fro lines.\nOga\nafocks neam. groshnichint trown setter, make hully the have soin;\nnow leaver, goses is love ever flove parch\nA may the losk formoren.\nMy shve chain\nlike assellodir; time abacc;\n6 their your ner yet\nInvericitam the aill the hight\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://github.com/rasbt/machine-learning-book/blob/main/ch15/ch15_part3.ipynb","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:31:43.780793Z","iopub.status.idle":"2022-03-09T07:31:43.781449Z","shell.execute_reply.started":"2022-03-09T07:31:43.781207Z","shell.execute_reply":"2022-03-09T07:31:43.781231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}